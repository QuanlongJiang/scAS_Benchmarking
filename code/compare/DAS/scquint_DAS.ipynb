{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1fce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "plt.switch_backend('agg')\n",
    "import seaborn as sns\n",
    "sns.set_style( \"white\" )\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "font_dirs = ['/home/jiangquanlong/miniconda3/envs/r_env/lib/python3.12/site-packages/matplotlib/mpl-data/fonts/ttf']\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)\n",
    "\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']  \n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef0d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sc(fname):\n",
    "    df = pd.read_csv(fname,header=0)\n",
    "    test_group = list(set(df['test_group']))[0]\n",
    "    df = df[df['test_group']==test_group]\n",
    "    df['pos'] = df['name'].str.split('_').str[1:3].str.join('_')\n",
    "    df = df.sort_values(by='p_value_adj')\n",
    "    df.index = df['pos']\n",
    "    return df[['pos','p_value_adj']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc107727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmats(fname):\n",
    "    df = pd.read_table(fname, header=0)\n",
    "    df['3end'] = df['chr'].astype(str) + '_' + df['downstreamES'].astype(str)\n",
    "    df['SE_pos'] = df['chr'].astype(str) + '_' + df['exonStart_0base'].astype(str) + '_' + df['exonEnd'].astype(str)\n",
    "    df['5end_3end'] = df['chr'].astype(str) + '_' + df['upstreamEE'].astype(str) + '_' + df['downstreamES'].astype(str)\n",
    "    df = df.sort_values(by='FDR')\n",
    "    return df[['3end','SE_pos','5end_3end','IncLevelDifference','FDR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a80fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf(fname):\n",
    "    pos_f = os.path.split(fname)[0] + '/leafcutter_cluster/sample_perind_numers.counts.gz'\n",
    "    with gzip.open(pos_f, 'rt') as file:  \n",
    "        lines = list(map(lambda l: l.strip().split(' '), file.readlines()))[1:]\n",
    "    clu_dict = {}\n",
    "    for line in lines:\n",
    "        chrom,start,end,clu_id = line[0].split(':')\n",
    "        clu_id = chrom + ':' + clu_id\n",
    "        if clu_id not in clu_dict:\n",
    "            clu_dict[clu_id] = [[],[]]\n",
    "        clu_dict[clu_id][0].append('_'.join([chrom,start,end]))\n",
    "        clu_dict[clu_id][1].append('_'.join([chrom,end]))\n",
    "    \n",
    "    df = pd.read_table(fname,header=0)\n",
    "    pos_list = []\n",
    "    three_end_list = []\n",
    "    for clu_id in df['cluster']:\n",
    "        poss = clu_dict[clu_id][0]; three_ends = clu_dict[clu_id][1]\n",
    "        pos_list.append(poss)\n",
    "        three_end_list.append(three_ends)\n",
    "    df['5end_3end'] = pos_list\n",
    "    df['3end'] = three_end_list\n",
    "    df['5end_3end_tuple'] = df['5end_3end'].apply(tuple)\n",
    "    df = df.sort_values('p.adjust').drop_duplicates(subset='5end_3end_tuple', keep='first')\n",
    "    df =  df.sort_values(by='p.adjust')\n",
    "    return df[['cluster','5end_3end','3end','p.adjust']]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ecf9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_intervals_rmats(list_A, list_B, tolerance=3):\n",
    "    # 将list_B转换为更快查找的格式\n",
    "    def parse_interval(interval):\n",
    "        parts = interval.split('_')\n",
    "        if len(parts) == 3:\n",
    "            return parts[0], int(parts[1]), int(parts[2])\n",
    "        elif len(parts) == 2:\n",
    "            return parts[0], int(parts[1])\n",
    "        else:\n",
    "            ...\n",
    "    # 创建一个字典，键是染色体，值是起始位置列表\n",
    "    b_intervals_by_chrom = {}\n",
    "    for interval_b in list_B:\n",
    "        chrom_b, start_b = parse_interval(interval_b)\n",
    "        if chrom_b not in b_intervals_by_chrom:\n",
    "            b_intervals_by_chrom[chrom_b] = []\n",
    "        b_intervals_by_chrom[chrom_b].append(start_b)\n",
    "    \n",
    "    common_intervals = []\n",
    "    \n",
    "    # 遍历list_A\n",
    "    for interval_a in list_A:\n",
    "        chrom_a, start_a,end_a = parse_interval(interval_a)\n",
    "        \n",
    "        # 只在同一染色体的区间中查找\n",
    "        if chrom_a not in b_intervals_by_chrom:\n",
    "            continue\n",
    "        \n",
    "        # 在同一染色体的起始位置中查找匹配\n",
    "        for start_b in b_intervals_by_chrom[chrom_a]:\n",
    "            if (abs(start_a - start_b) <= tolerance) or (abs(end_a - start_b) <= tolerance):\n",
    "                common_intervals.append(interval_a)\n",
    "                break\n",
    "    \n",
    "    return common_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcfc256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_intervals_leaf(list_A, list_B, tolerance=3):\n",
    "    # 将list_B转换为更快查找的格式\n",
    "    def parse_interval(interval):\n",
    "        parts = interval.split('_')\n",
    "        if len(parts) == 3:\n",
    "            return parts[0], int(parts[1]), int(parts[2])\n",
    "        elif len(parts) == 2:\n",
    "            return parts[0], int(parts[1])\n",
    "        else:\n",
    "            ...\n",
    "    # 创建一个字典，键是染色体，值是起始位置列表\n",
    "    b_intervals_by_chrom = {}\n",
    "    for interval_b in list_B:\n",
    "        chrom_b, start_b = parse_interval(interval_b)\n",
    "        if chrom_b not in b_intervals_by_chrom:\n",
    "            b_intervals_by_chrom[chrom_b] = []\n",
    "        b_intervals_by_chrom[chrom_b].append(start_b)\n",
    "    \n",
    "    common_intervals = []\n",
    "    \n",
    "    for interval_a_list in list_A:\n",
    "        found = False\n",
    "        for interval_a in interval_a_list:\n",
    "            chrom_a, start_a, end_a = parse_interval(interval_a)\n",
    "            if chrom_a not in b_intervals_by_chrom:\n",
    "                continue\n",
    "            for start_b in b_intervals_by_chrom[chrom_a]:\n",
    "                if abs(start_a - start_b) <= tolerance or abs(end_a - start_b) <= tolerance:\n",
    "                    common_intervals.append(interval_a)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "    return common_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff4f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(lst):\n",
    "    seen = set()\n",
    "    return [x for x in lst if not (x in seen or seen.add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2d25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aucc(ranked_genes_bulk, ranked_genes_sc, k,tool, plot=False):\n",
    "    ranked_genes_sc = remove_duplicates( ranked_genes_sc)\n",
    "    intersection_counts = []\n",
    "    for i in range(1, k + 1):\n",
    "        top_bulk = ranked_genes_bulk[:i]\n",
    "        top_sc = ranked_genes_sc[:i]\n",
    "        if tool == 'rmats':\n",
    "            intersection = len(find_similar_intervals_rmats(top_bulk, top_sc))\n",
    "        else:\n",
    "            intersection = len(find_similar_intervals_leaf(top_bulk, top_sc))\n",
    "        intersection_counts.append(intersection)\n",
    "\n",
    "    # 计算面积（Raw AUCC）\n",
    "    raw_aucc = sum(intersection_counts)\n",
    "\n",
    "    # 归一化：最大面积是 k*(k+1)/2\n",
    "    max_area = k * (k + 1) / 2\n",
    "    normalized_aucc = raw_aucc / max_area\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(range(1, k + 1), intersection_counts, label='Concordance Curve', color='blue')\n",
    "        plt.fill_between(range(1, k + 1), intersection_counts, alpha=0.3, color='blue')\n",
    "        plt.title(f'Concordance Curve (AUCC = {normalized_aucc:.3f})')\n",
    "        plt.xlabel('Top-k Genes')\n",
    "        plt.ylabel('Intersection Size')\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return normalized_aucc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f8218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aucc_gene(name,ranked_genes_bulk, ranked_genes_sc, k,tool, plot=False):\n",
    "    def find_same_gene(list_A,list_B):\n",
    "        common_genes = []\n",
    "        for gene in list_A:\n",
    "            if gene in list_B:\n",
    "                common_genes.append(gene)\n",
    "        return common_genes\n",
    "        \n",
    "    ranked_genes_sc = remove_duplicates(ranked_genes_sc)\n",
    "    #convert to gene id\n",
    "    if name == 'data9_a2i':\n",
    "        ranked_genes_sc = convert_to_geneid(ranked_genes_sc[:k+1],mm_anno_df)\n",
    "        ranked_genes_bulk = convert_to_geneid(ranked_genes_bulk[:k+1],mm_anno_df)\n",
    "    else:\n",
    "        ranked_genes_sc = convert_to_geneid(ranked_genes_sc[:k+1],hg_anno_df)\n",
    "        ranked_genes_bulk = convert_to_geneid(ranked_genes_bulk[:k+1],hg_anno_df)\n",
    "    intersection_counts = []\n",
    "    for i in range(1, k + 1):\n",
    "        top_bulk = ranked_genes_bulk[:i]\n",
    "        top_sc = ranked_genes_sc[:i]\n",
    "        intersection = len(find_same_gene(top_bulk, top_sc))\n",
    "        intersection_counts.append(intersection)\n",
    "\n",
    "    # 计算面积（Raw AUCC）\n",
    "    raw_aucc = sum(intersection_counts)\n",
    "\n",
    "    # 归一化：最大面积是 k*(k+1)/2\n",
    "    max_area = k * (k + 1) / 2\n",
    "    normalized_aucc = raw_aucc / max_area\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(range(1, k + 1), intersection_counts, label='Concordance Curve', color='blue')\n",
    "        plt.fill_between(range(1, k + 1), intersection_counts, alpha=0.3, color='blue')\n",
    "        plt.title(f'Concordance Curve (AUCC = {normalized_aucc:.3f})')\n",
    "        plt.xlabel('Top-k Genes')\n",
    "        plt.ylabel('Intersection Size')\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return normalized_aucc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d64edd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_geneid(positions,df):\n",
    "    result_genes = []\n",
    "    \n",
    "    for pos in positions:\n",
    "        if isinstance(pos,list):\n",
    "            pos = pos[0]\n",
    "        pos = pos.split('_')\n",
    "        if len(pos) == 3:\n",
    "            chrom, start, end = pos\n",
    "        elif len(pos) == 2:\n",
    "            chrom, start = pos\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        start = int(start);\n",
    "        # 找到相同染色体的基因\n",
    "        chr_genes = df[df['chrom'] == chrom].copy()\n",
    "        \n",
    "        if len(chr_genes) == 0:\n",
    "            result_genes.append(\"No gene found\")\n",
    "            continue\n",
    "            \n",
    "        # 找到包含start位置的基因\n",
    "        containing_genes = chr_genes[\n",
    "            (chr_genes['start'] <= start) & (chr_genes['end'] >= start)\n",
    "        ].copy()\n",
    "        \n",
    "        if len(containing_genes) == 0:\n",
    "            result_genes.append(\"No gene found\")\n",
    "            continue\n",
    "            \n",
    "        # 如果有protein_coding的基因，优先选择protein_coding\n",
    "        protein_coding = containing_genes[containing_genes['gene_type'] == 'protein_coding']\n",
    "        \n",
    "        if len(protein_coding) > 0:\n",
    "            # 如果有多个protein_coding基因，选择第一个\n",
    "            best_gene = protein_coding.iloc[0]\n",
    "        else:\n",
    "            # 如果没有protein_coding，选择第一个基因\n",
    "            best_gene = containing_genes.iloc[0]\n",
    "        \n",
    "        result_genes.append(best_gene['gene_id'])\n",
    "    \n",
    "    return result_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a368cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anno_df(f):\n",
    "    df = pd.read_csv(f, sep='\\t', usecols=['gene_id', 'gene_type', 'position'])\n",
    "    df[['chrom', 'coords']] = df['position'].str.split(':', expand=True)\n",
    "    df[['start', 'end']] = df['coords'].str.split('-', expand=True).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebb2febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_files = {'data2_24h':'/disk1/2.methods_AS/3.scquint/2.stemCell_GSE52529/Myoblast_Cell_T0_vs_Myoblast_Cell_T24_intron_groups.csv',\n",
    "           'data2_48h':'/disk1/2.methods_AS/3.scquint/2.stemCell_GSE52529/Myoblast_Cell_T0_vs_Myoblast_Cell_T48_intron_groups.csv',\n",
    "           'data2_72h':'/disk1/2.methods_AS/3.scquint/2.stemCell_GSE52529/Myoblast_Cell_T0_vs_Myoblast_Cell_T72_intron_groups.csv',\n",
    "           'data8_ipsc':'/disk1/2.methods_AS/3.scquint/8.iPSC_GSE85908/Motor_neurons_vs_Induced_pluripotent_cells.csv',\n",
    "           'data9_a2i':'/disk1/2.methods_AS/3.scquint/9.CSC_E-MTAB-2600/serum_vs_a2i.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "254b8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmats_files = {'data2_24h':'/disk4/humanData/2.stemCell_GSE52529/bulk_spl/bulk_24hrs/SE.MATS.JCEC.txt',\n",
    "               'data2_48h':'/disk4/humanData/2.stemCell_GSE52529/bulk_spl/bulk_48hrs/SE.MATS.JCEC.txt',\n",
    "               'data2_72h':'/disk4/humanData/2.stemCell_GSE52529/bulk_spl/bulk_72hrs/SE.MATS.JCEC.txt',\n",
    "              'data8_ipsc':'/disk4/humanData/3.iPSC_GSE85908/bulk_spl/Induced_pluripotent_cells/SE.MATS.JCEC.txt',\n",
    "              'data9_a2i':'/disk4/mouseData/CSC_E-MTAB-2600/bulk_spl/serum_bulk/SE.MATS.JCEC.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e9abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_files = {'data2_24h':'/disk4/humanData/2.stemCell_GSE52529/bulk_spl/bulk_24hrs_groups_cluster_significance.txt',\n",
    "             'data2_48h':'/disk4/humanData/2.stemCell_GSE52529/bulk_spl/bulk_48hrs_groups_cluster_significance.txt',\n",
    "             'data2_72h':'/disk4/humanData/2.stemCell_GSE52529/bulk_spl/bulk_72hrs_groups_cluster_significance.txt',\n",
    "             'data8_ipsc':'/disk4/humanData/3.iPSC_GSE85908/bulk_spl/Induced_pluripotent_cells_groups_cluster_significance.txt',\n",
    "             'data9_a2i':'/disk4/mouseData/CSC_E-MTAB-2600/bulk_spl/a2i_bulk_groups_cluster_significance.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bd2b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_anno_df = get_anno_df(f='/disk1/0.Genome/gencode.v31/GenomeAnnotation.txt')\n",
    "mm_anno_df = get_anno_df(f='/disk1/0.Genome/gencode.vM25/GenomeAnnotation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "941cfe61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2_24h\n",
      "data2_48h\n",
      "data2_72h\n",
      "data8_ipsc\n",
      "data9_a2i\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "gene_result = {}\n",
    "k = 200\n",
    "\n",
    "for name in sc_files:\n",
    "    print(name)\n",
    "    result[name] = {};gene_result[name] = {}\n",
    "    sc_f = sc_files[name]; rmats_f = rmats_files[name]; leaf_f = leaf_files[name]\n",
    "    sc_pval = get_sc(sc_f)\n",
    "    rmats_pval = get_rmats(rmats_f)\n",
    "    leaf_pval = get_leaf(leaf_f)\n",
    "    tool = 'rmats'\n",
    "    aucc_score = compute_aucc(rmats_pval['5end_3end'].to_list(),sc_pval['pos'].to_list(), k=k, tool=tool)\n",
    "    result[name][tool] = aucc_score\n",
    "    tool = 'leaf'\n",
    "    aucc_score = compute_aucc(leaf_pval['5end_3end'].to_list(),sc_pval['pos'].to_list(), k=k, tool=tool)\n",
    "    result[name][tool] = aucc_score\n",
    "    #################gene level##################\n",
    "    tool = 'rmats'\n",
    "    aucc_score = compute_aucc_gene(name,rmats_pval['5end_3end'].to_list(),sc_pval['pos'].to_list(), k=k,tool=tool)\n",
    "    gene_result[name][tool] = aucc_score\n",
    "    tool = 'leaf'\n",
    "    aucc_score = compute_aucc_gene(name,leaf_pval['5end_3end'].to_list(),sc_pval['pos'].to_list(), k=k,tool=tool)\n",
    "    gene_result[name][tool] = aucc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d393ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data2_24h': {'rmats': 0.17405940594059405, 'leaf': 0.15445544554455445},\n",
       " 'data2_48h': {'rmats': 0.2091089108910891, 'leaf': 0.17544554455445543},\n",
       " 'data2_72h': {'rmats': 0.2857425742574257, 'leaf': 0.2801980198019802},\n",
       " 'data8_ipsc': {'rmats': 0.1782178217821782, 'leaf': 0.2104950495049505},\n",
       " 'data9_a2i': {'rmats': 0.22851485148514852, 'leaf': 0.16455445544554456}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c2d6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data2_24h': {'rmats': 0.11108910891089109, 'leaf': 0.11445544554455446},\n",
       " 'data2_48h': {'rmats': 0.09702970297029703, 'leaf': 0.10435643564356435},\n",
       " 'data2_72h': {'rmats': 0.14118811881188117, 'leaf': 0.17207920792079207},\n",
       " 'data8_ipsc': {'rmats': 0.11762376237623762, 'leaf': 0.17603960396039603},\n",
       " 'data9_a2i': {'rmats': 0.21841584158415842, 'leaf': 0.14237623762376236}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6df6c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(result, orient='index')\n",
    "df.to_csv('scQuint_AUCC.{}.csv'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c767a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(gene_result,orient='index')\n",
    "df.to_csv('scQuint_AUCC.gene.{}.csv'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48242009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
